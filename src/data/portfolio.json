{
  "basics": {
    "name": "Dr. Tarik Crnovrsanin",
    "picture": "CrnovrsaninTarik_Northeastern_Photov2.jpg",
    "label": "",
    "headline": "",
    "summary": "I am a Senior Software engineer and previously a PostDoc with Cody Dunne at Data Visualization at Khoury of Northeastern University. My research focuses on visualizations, techniques, and systems for various datasets, including static and dynamic networks, radio signals, and fire data. I'm an past ORISE fellowship participant in explainable AI for drone detection. \n\nMy enjoyment of learning and conducting research extends beyond my graduate career. I combine my love of research and 7+ years of Fused Deposition Modeling (FDM) printing to develop new flinging foam methods. I 3D design and engineer products from concept to full production. I also utilize my visualization skills to create better customer shopping experiences by providing UI to fully visualize/render and customize their purchases. ",
    "website": "https://tarikc.net",
    "email": "",
    "region": "Boston, Massachusetts",
    "location": {},
    "phone": "",
    "profiles": [
      {
        "network": "GitHub",
        "username": "turokhunter",
        "url": "https://github.com/Turokhunter",
        "iconName": "github"
      },
      {
        "network": "Linkedin",
        "url": "https://www.linkedin.com/in/tarik-crnovrsanin-8b0aa3100/",
        "username": "@Tarik Crnovrsanin",
        "iconName": "linkedin"
      }
    ]
  },
  "skills": [
    {
      "name": "C++",
      "level": "Expert",
      "rating": 5,
      "yearsOfExperience": 10,
      "keywords": []
    },
    {
      "name": "Python",
      "level": "Advance",
      "rating": 4,
      "yearsOfExperience": 4,
      "keywords": []
    }
  ],
  "selectedprojects": [
    {
      "title": "Amoeba: Visual metaphor for discourse forums",
      "image": "Amoeba.png",
      "summary": "Discussion forums allow individuals across the world to express their opinions on a variety of topics. We introduce Amoebas, a visual metaphor for discussion forum threads that allows researchers to examine social interactions, compare thread structure, and make hypotheses about the patterns or trends of these forums.",
      "link": "/projects#research",
      "position": "50% 50%"
    },
    {
      "title": "SetMLVis: Set Visualization for Object Detection",
      "image": "dac.png",
      "summary": "Traditional metrics like average precision and recall may not fully capture performance differences. We developed an interactive system called SetMLVis that addresses the challenges in comparing object detection models by proposing a novel approach using set visualizations for model-to-model comparison.",
      "link": "/projects#research",
      "position": "50% 50%"
    },
    {
      "title": "Product Customizer",
      "image": "Color-picker-v2.png",
      "summary": "Created a customizer tool for customers to make it easier to see what the 3D-printed part will look like with their color selections. Over 90% of products on outofdarts.com use my customizer code. ",
      "link": "/projects#design"
    }
  ],
  "selectedpapers": [
    {
      "title": "Indy Survey Tool",
      "summary": "Introducing Indy Survey Tool, a platform that simplifies companion website creation for survey papers, enables authors to update and explore survey data easily. Users can pinpoint correlations among paper categories through combined filters and correlation matrix visualizations, revealing insights and potential research gaps.",
      "image": "IndySurvey.png",
      "link": "/publications#Indy-Survey"
    },
    {
      "title": "What Would a Graph Look Like in This Layout? A Machine Learning Approach to Large Graph Visualization",
      "summary": "Using graph kernels, we present a machine-learning approach to large graph visualization based on computing graphs' topological similarity. Our approach can show what a given graph would look like in different layouts and estimate its corresponding aesthetic metrics.",
      "image": "GraphLook.png",
      "link": "/publications#GraphML",
      "position": "50% 50%"
    },
    {
      "title": "An Incremental Layout Method for Visualizing Online Dynamic Graphs",
      "summary": "A novel incremental layout method designed for online dynamic graphs that uses the concept of 'energy' to move nodes with high energy into low energy states. Our resulting visualization maintains readability of the graph structure and is efficient in laying out these changing networks.",
      "image": "Incremental.png",
      "link": "/publicationsIncremental-Layout",
      "position": "90% 50%"
    }
  ],
  "projects": [
    {
      "title": "Research",
      "summary": "My research spans networks, information visualization, and algorithms. Specifically, it focuses on the implementation of new algorithms to improve visual understanding and analysis. The projects below are part of my Master's and Ph.D. research. Not all of these projects became papers but nonetheless have interesting elements worth sharing.",
      "entries": [
        {
          "title": "Amoeba: Visual metaphor for discourse forums",
          "image": "Amoeba.png",
          "shortDesc": "Discussion forums allow individuals across the world to express their opinions on a variety of topics. We introduce Amoebas, a visual metaphor for discussion forum threads that allows researchers to examine social interactions, compare thread structure, and make hypotheses about the patterns or trends of these forums.",
          "tags": ["C++", "OpenGL", "OpenCL"],
          "html": [
            {
              "image": {
                "src": "Amoeba.png",
                "caption": "An example of an Amoeba. Each circle represents a post. The starting post is placed in the center. Replies to the starting post are called first-level replies are placed around the center. Replies to replies or reply chains create the tendrils of the Amoeba. The Amoebas encode three channels to color. The color of the circle maps to post information, while the tendril’s color maps to the aggregated values of the reply chain. Lastly, the outer skin color map information about the thread.",
                "width": 540
              }
            },
            {
              "p": "Discussion forums allow individuals across the world to express their opinions on a variety of topics. Studying these discussion forums provides insight into interesting, trending topics and how conversation and behavior evolve. However, gaining insight from these data sets is challenging due to their large, complex nature. In this paper, we introduce Amoebas, a visual metaphor for discussion forum threads that allows researchers to examine social interactions, compare thread structure, and make hypotheses about the patterns or trends of discussion forums. The Amoebas metaphor provides new classifications for discussion threads that allow for quick identification of patterns. Below, demonstrate an example of a MOOC dataset visualized using the amoeba metaphor. "
            },
            {
              "image": {
                "src": "figure-game.png",
                "caption": "Discussion forum from MOOC course on Game Theory. Regions are partition by sub forums. The inner layer is mapped to user’s affiliation in the class, while the outer layer is mapped to thread view count. MOOC discussion forums contain more complex Amoebas than other types of forums. Problem set sub forum has the most threads and the views. Both anonymous and community TAs are found in the Problem set as well. One exception stands out, a thread in general discussion posted by community TA has many anonymous responses"
              }
            }
          ]
        },
        {
          "title": "SetMLVis: Set Visualization for Object Detection",
          "image": "dac.png",
          "shortDesc": "Traditional metrics like average precision and recall may not fully capture performance differences, so the authors advocate for directly comparing models using set visualizations to reveal unique strengths and weaknesses. We developed an interactive system called SetMLVis that addresses the challenges in comparing object detection models by proposing a novel approach using set visualizations for model-to-model comparison.",
          "tags": ["JS", "Svelte", "JupyterLab Widget"],
          "html": [
            {
              "image": {
                "src": "dac.png",
                "caption": "Figure A. An example of the SetMLVis system visualizing satellite data",
                "width": 1024
              }
            },
            {
              "p": "This work explores the challenges in comparing object detection models and proposes a novel approach using set visualizations to enable model-to-model comparison. Object detection models are crucial across various industries, but selecting the right one for a specific application can be complex due to the multitude of model types and evaluation criteria. Traditional evaluation metrics like average precision and average recall may not fully capture performance differences between models. The proposed methodology involves comparing models directly to each other using set visualizations, which allows for intuitive queries to be made about model behavior and facilitates the identification of unique strengths and weaknesses. We developed an interactive visualization system called SetMLVis and demonstrated its effectiveness compared to traditional visualization methods."
            },
            {
              "materials": {
                "GitHub": "https://github.com/VisDunneRight/setmlvis",
                "PyPI": "https://pypi.org/project/setmlvis/",
                "Video Presentation": "https://www.youtube.com/watch?v=2OGFn_Jle0Y&ab_channel=Voxel51"
              }
            }
          ]
        },
        {
          "title": "Indy Survey Tool",
          "image": "IndySurvey.png",
          "shortDesc": "We introduce Indy Survey Tool, a tool that simplifies the creation of companion websites for survey papers, aiding authors in developing interactive platforms to explore and update survey information easily. By offering combined filters and correlation matrix visualizations, the tool allows users to identify correlations between categorizations of papers, facilitating deeper insights and highlighting potential research gaps.",
          "tags": ["JS", "Svelte"],
          "html": [
            {
              "image": {
                "src": "indy-teaser-cropped.png",
                "caption": "Figure A. An example of how the Indy Survey Tool we present was used in recent survey on Immersive Analytics. The left panel (1) lets users filter using a search bar, timeline, and topic selector. The top bar (2) provides information about the survey and how to add new entries. The center (3)  shows a short summary of each included paper. The collapsible visualization panel (4) on the right shows a correlation matrix for two selected dimensions. Interacting with the left and right panels filters the papers displayed in the center.  Upon selection of a paper, a detail view pops up with all of its information (not shown). .",
                "width": 720
              }
            },
            {
              "p": "Survey companion websites allow users to explore collected survey information more deeply, as well as update or add entries for papers. These sites can help information stay relevant past the original release date of the survey paper. However, creating and maintaining a website can be laborious and difficult, especially when authors might not be experienced with programming. We introduce Survey Indy tool to help authors develop companion websites for survey papers across diverse fields of study.The tool's core aim is to identify correlations between categorizations of papers. To accomplish this, the tool offers multiple combined filters and correlation matrix visualizations that enable users to explore the data from diverse perspectives. The tool's visualizations, list of papers, and filters are harmoniously integrated and highly responsive, providing users with feedback based on their selections. Identifying correlations in survey papers is a pivotal aspect of research, as it can enable the recognition of common combinations of categorizations within the papers---as well as highlight any omissions. The versatility of Survey Indy tool enables researchers to delve into the correlations between categorizations in survey data, an essential aspect of research that can reveal gaps in the literature and highlight promising areas for future exploration."
            },
            {
              "materials": {
                "PDF": "https://osf.io/um9gs/download",
                "Preprint": "https://osf.io/um9gs/",
                "Supplement": "https://osf.io/tdhqn/",
                "Code": "https://github.com/VisDunneRight/Indy-Survey-Tool",
                "DOI": "https://doi.org/10.1109/VIS54172.2023.00038"
              }
            }
          ]
        },
        {
          "title": "Batch Simulation Tool",
          "image": "sim_vs_true.svg",
          "shortDesc": "Acquiring diverse UAV data for predictive tasks is challenging due to laborious and costly real-world data collection, leading to increased reliance on simulators. However, the multitude of available simulators poses challenges, and no comparative evaluation has been conducted regarding their effectiveness in replicating real-world scenarios. We introduce an open-source batch simulation tool to streamline data generation, leveraging real flight data to validate simulated missions.",
          "tags": ["Python", "Bash", "PX4", "ArduPilot"],
          "html": [
            {
              "image": {
                "src": "sim_vs_true.svg",
                "caption": "A comparison of ground truth with various simulators supported by the batch tool.  The rows indicate different flight patterns, and the columns are the different simulators and middleware.",
                "width": 720
              }
            },
            {
              "p": "Acquiring realistic and varied UAV data has become a central part of many UAV-related predictive tasks. However, creating this dataset is often laborious, with the constant need to reset the flight conditions, and resource-intensive due to the associated costs of drones. Consequently, individuals turn to simulators when a large amount of the data is needed for tasks such as training machine learning techniques.  Yet, many simulators are available, introducing their own challenges, ranging from setup complexities to varying degrees of fidelity in emulating real-world scenarios. Despite the prevalent use of simulators, to the best of our knowledge, no one has compared the effectiveness of said to each other and their capabilities to imitate real-world data. In this work, we endeavor to bridge this gap by evaluating the accuracy of a simulated flight to a real flight while also assessing the performance of different simulators. Additionally, we introduce an open-source batch tool aimed at streamlining the data generation process and facilitating the creation of large datasets, offering support for generating flight paths across multiple simulators. We leverage real flight data from the PX4 flight log repository and produce missions that are then simulated using our batch tool."
            }
          ]
        },
        {
          "title": "Multi-Level Maps",
          "image": "mgmap.png",
          "shortDesc": "This work proposes a method for visualizing graphs using multi-level maps to enhance the representation of underlying structures and neighborhood information. It introduces a technique that utilizes graph hierarchies to create sub-graph regions at different zoom levels, employing a spiral placement algorithm to arrange disconnected graph components compactly. ",
          "tags": ["C++", "OpenGL"],
          "html": [
            {
              "image": {
                "src": "MOOCv4.png",
                "caption": "Figure A. A MOOC Forum of an Asset Pricing course (left). A zoomed in section of the \"Google hangout\" sub-forum at Level 2 and Level 3 (top right) and the \"Quizzes and Homeworks\" sub-forum at Level 2 (bottom right). The most popular sub-forum sections are \"Quizzes and Homework\", \"Lectures\" and \"General Discussion\"",
                "width": 720
              }
            },
            {
              "p": "A single conventional node-link diagram often fails to fully capture a graph's underlying structure, embedded clusters, or neighborhood information. The ability to visually overlay additional information on top of a graph can produce a richer visualization of the graph.  Map metaphors have been used for non-geospatial data due to their intuitive nature and widespread use.    This work presents a method for drawing a graph with superimposed multi-level maps. Our method uses either a provided or derived graph hierarchy to create sub-graph regions of the map at varying zoom levels. We use a spiral placement algorithm to arrange the disconnected components of the graph compactly. Our multi-level map generation algorithm can use any polygon generation technique to create regions if there is a way to identify whether two polygons share an edge. We experiment with different bounding shapes, which are approximate areas of the components to use in the spiral placement algorithm and evaluate their impact on its compactness through a qualitative study. Furthermore, we demonstrate the effectiveness of our method by applying it to graphs that contain an inherent hierarchy, a derived hierarchy, or sets. "
            },
            {
              "image": {
                "src": "stackv2.png",
                "caption": "Figure B. A typical day at Stack Overflow. Tag information is used to create a hierarchy. The top eight tags are colored. A zoomed-in section of the border among  Android, Java, and Javascript (top right) shows clear intermixing among these tags with a stronger mix between Java and Android. This provides a striking difference when compared with C++ and Python (bottom right) where only minor mixing occur with the windows tag",
                "width": 720
              }
            }
          ]
        },
        {
          "title": "Finding Similiarities in DB Queries",
          "image": "SDSS.png",
          "shortDesc": "We looked into how unsupervised learning can be utilized to cluster similar queries together. This can enable database admins and users to understand the most common queries written and where improvement in managing or writing queries can occur.  These types of visualization can help improve the efficiency of databases by pointing out where databases can be restructured to improve queries and make them easier to write.",
          "tags": ["JS", "Python", "MongoDB"],
          "html": [
            {
              "image": {
                "src": "SDSS.png",
                "caption": ""
              }
            },
            {
              "p": "The tool was built to explore queries written to a database. It takes in all queries and uses different unsupervised learning methods to cluster similar queries. At the time of writing, the tool supports UMAP and t-SNE. The similarities are based on how the query is structured, with similar functions supported based on existing literature. "
            },
            {
              "p": "To help render millions of queries, a hexagon heatmap is used to reduce the number of points drawn. The darker the color, the more queries are found at the location. Mousing over shows the number of queries. Selecting a hexagon shows all the queries grouped together, and selecting a second point allows for comparison between the two points."
            }
          ]
        }
      ]
    },
    {
      "title": "Web Projects",
      "summary": "When I find the time (haha), I apply my visualization and programming skillset to some exciting side projects.",
      "entries": [
        {
          "title": "Khoury Vis Lab Website",
          "image": "khouryLabv3.png",
          "shortDesc": "I created our Khoury vis lab website, which is modeled after this personal site. To make the process of updating the website as easy as possible, the entire website is run using JSON files. Cody Dunne and Daniel Kerrigan have continued to extend the site and provide means to update the JSON file from pull requests, making the automation even better.",
          "tags": ["JS", "React"],
          "html": [
            {
              "image": {
                "src": "khouryLabv2.png",
                "caption": ""
              }
            },
            {
              "p": "I created our Khoury vis lab website, which is modeled after this personal site. To make the process of updating the website as easy as possible, the entire website is run using JSON files. Cody Dunne and Daniel Kerrigan have continued to extend the site and provide means to update the JSON file from pull requests, making the automation even better."
            },
            {
              "materials": {
                "Website": "https://vis.khoury.northeastern.edu/",
                "GitHub": "https://github.com/KhouryVis/khouryvis.github.io"
              }
            }
          ]
        },
        {
          "title": "3D Color and Option Picker",
          "image": "STLViewer.png",
          "shortDesc": "3D printing's key strength lies in customer customization, allowing them to personalize products by selecting colors and components. However, many platforms lack the immediate visual representation of these choices, leaving users uncertain about their selections. To address this, I developed the STL Viewer and menu system, enabling real-time updates of 3D printed files to showcase customers' chosen colors and components.",
          "tags": ["JS", "Shopify", "Three.js"],
          "html": [
            {
              "p": "One of the major strengths of 3D printing is the ability for the customers to customize their product by changing the color of the parts or choosing from a set of components to fit their style and personality.  Though most sites offer the ability to customize the user's purchase selection, they do not provide the means for the user to visually see their choice immediately.  There are so many possible parts and color choices that it is unreasonable for every permutation to be photographed. The lack of immediate feedback can leave the user unsure how particular color and parts combinations will look. Therefore, I created the STL Viewer and menu system that loads 3D printed files and updates them based on the customer's colors and choices in real-time."
            },
            {
              "image": {
                "src": "STLViewer.png",
                "caption": "Figure B. Illustration of the menu system and STL Viewer. The user chooses what colors and options they would prefer (on the right), and the results are displayed on the left. The Viewer allows for panning and zooming so that the user has a better idea of their choices made.",
                "width": 720
              }
            },
            {
              "p": "We automatically generate the menu system from two JSON files. One JSON file describes where the STL file location, camera position, and product breakdown. The second JSON file contains information about filaments, such as cost tier and color in hex. This allows for a global filament file that makes adding and removing filament across all items easy. The left visualization provides basic capabilities such as zoom and pan and updates instantly based on the user selection from the menu on the right. The user selects a color by either the section menu or individually customizing each component in the section. The dropdown menu separates color based on the cost tier. As the visualization on the right cannot capture the exact color, or any nuances the filament might have such as glitter, mousing over each color provides a color correct swatch. When choosing a more expensive filament, the price changes and text updates to indicate the price difference in that section."
            },
            {
              "link": {
                "text": "For a live example of the code running, please check Herja listing:",
                "url": "https://outofdarts.com/products/herja-3d-parts-hardware-kit?_pos=1&_psq=herja&_ss=e&_v=1.0",
                "linkText": "Herja 3D Parts + Hardware Kit"
              }
            },
            {
              "link": {
                "text": "For those interested in the implementation, starting code can be found in GitHub:",
                "url": "https://outofdarts.com/collections/jupiter/products/rival-jupiter-blaster-kit-build-it-yourself",
                "linkText": "Github"
              }
            }
          ]
        },
        {
          "title": "Menu Creator",
          "image": "MenuCreator.png",
          "shortDesc": "Innovation in design can trigger a cascade of effects. While the above menu system enhances customer product customization, it unintentionally complicates the menu creation process. JSON files, though commonly used for data, pose a challenge for individuals without specific training. To address this, I introduce the Menu Creator tool, simplifying and standardizing the construction of JSON files.",
          "tags": ["JS", "React"],
          "html": [
            {
              "p": "As with any design, one innovation can cause a cascading effect. The menu system shown above is great for the customers as it provides more customization of products. An unintended by-product of such a design is the act of creating said menu system becomes more complicated. Though JSON files are a common format for passing data, they are not intuitive to construct, especially for an average individual lacking training in creating such listings. To combat this issue and standardize the JSON file's construct, we create a Menu Creator tool."
            },
            {
              "image": {
                "src": "MenuCreator.png",
                "caption": "Figure C. The staff creates and populates options on the left. A live preview of the choices are shown on the top right. Lastly, variants and mapping of variants are done on the bottom right.",
                "width": 720
              }
            },
            {
              "p": "The tool makes the process of generating the listing considerably easier. The staff can create one of three types of options; dropdown, color picker, or checkbox. More complex options are offered when the item in question needs a 3D render of it.  The tool supports duplication and reorganization and shows a live preview of the options and their selections. Once the staff is satisfied with their choice, they can use the \"Set Price\" button to create variants needed for Shopify. Variants are what Shopify uses to set prices on a combination of options. Shopify only allows 99 variants and three options. This small selection is quite limiting for 3D printed objects with 20 color choices and multiple options.  We overcome Shopify's limitation by allowing the staff to create price buckets, allowing multiple option combinations to map to the same variant or price bucket. The buckets can be made manually or automatically through the auto-populate feature."
            },
            {
              "link": {
                "text": "For a live example of the code running, please check out the demo:",
                "url": "https://turokhunter.github.io/Menu-Creator/",
                "linkText": "Git Live Example"
              }
            },
            {
              "link": {
                "text": "For those interested in the implementation, the code can be found in GitHub:",
                "url": "https://github.com/Turokhunter/Menu-Creator",
                "linkText": "Github"
              }
            }
          ]
        }
      ]
    },
    {
      "title": "3D design",
      "summary": "Here are some 3D design projects I worked on as part of a hobby turned side business. These projects scratch the same itch conducting dose. They allow me to combine my years of research and additive manufacturing experience into a new domain.",
      "entries": [
        {
          "title": "Jupiter",
          "image": "JupiterOldvsNew.png",
          "shortDesc": "This project was the first full blaster I created in collaboration with Luke (Out of Darts). Luke created several prototypes showing the possibility of having a minimized Rival Blaster (Fig. A Left). He asked me to improve the prototype design and create something that he could sell to his customers. Final version is on the right.",
          "tags": ["CAD", "Fusion 360"],
          "html": [
            {
              "p": "This is the first full blaster I created in collaboration with Luke (Out of Darts). Luke created several prototypes showing the possibility of having a minimized Rival Blaster (Fig. A Left). He asked me to improve the prototype design and create something that he could sell to his customers, shown in Fig. A Right."
            },
            {
              "image": {
                "src": "JupiterOldvsNew.png",
                "caption": "Figure A. Evolution of Jupiter. Prototype version on left and final version on the right.",
                "width": 720
              }
            },
            {
              "p": "Beyond the visual enhancement, I implemented several Quality of Life improvements and additional features. Externally, I completely redesigned the body to hide all wire channels, improved the grip, added a battery tray, and provided a comfortable placement of the trigger finger.  Internally, some changes include ease of assembling and response trigger press.  I also replaced a friction-fit clip lock mechanism with a more durable ball detent style. For a complete look at the modification, please check out the video on the left, and Jupiter's hidden features can be found in the video on the right."
            },
            [
              {
                "video": {
                  "src": "https://www.youtube.com/embed/nvSVqwGUw-E",
                  "height": 210,
                  "allow": "accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                }
              },
              {
                "video": {
                  "src": "https://www.youtube.com/embed/A4QA7Ux4oYA",
                  "height": 210,
                  "allow": "accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                }
              }
            ],
            {
              "p": "The Jupiter has released to high praise and, as of the time of writing this, has over 2 million collective views. A review of the blaster can be found in the video below from one of the most popular Nerf channels."
            },
            {
              "video": {
                "src": "https://www.youtube.com/embed/Yv2yhSZJvL4",
                "width": 374,
                "height": 210,
                "allow": "accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
              }
            }
          ]
        }
      ]
    }
  ],
  "publications": {
    "journal": [
      {
        "title": "Investigating the visual utility of differentially private scatterplots",
        "year": "2023",
        "authors": [
          "Liudas Panavas",
          "Tarik Crnovrsanin",
          "Jane Lydia Adams",
          "Jonathan Ullman",
          "Ali Sargavad",
          "Melanie Tory",
          "Cody Dunne"
        ],
        "hashLink": "differentially",
        "venue": "IEEE Transactions on Visualization and Computer Graphics—TVCG",
        "abstract": "Increasingly, visualization practitioners are working with, using, and studying private and sensitive data. There can be many stakeholders interested in the resulting analyses-but widespread sharing of the data can cause harm to individuals, companies, and organizations. Practitioners are increasingly turning to differential privacy to enable public data sharing with a guaranteed amount of privacy. Differential privacy algorithms do this by aggregating data statistics with noise, and this now-private data can be released visually with differentially private scatterplots. While the private visual output is affected by the algorithm choice, privacy level, bin number, data distribution, and user task, there is little guidance on how to choose and balance the effect of these parameters. To address this gap, we had experts examine 1,200 differentially private scatterplots created with a variety of parameter choices and tested their ability to see aggregate patterns in the private output (i.e. the visual utility of the chart). We synthesized these results to provide easy-to-use guidance for visualization practitioners releasing private data through scatterplots. Our findings also provide a ground truth for visual utility, which we use to benchmark automated utility metrics from various fields. We demonstrate how multi-scale structural similarity (MS-SSIM), the metric most strongly correlated with our study's utility results, can be used to optimize parameter selection. A free copy of this paper along with all supplemental materials is available at <a href=\"https://osf.io/wej4s/\">osf.io/wej4s</a>.",
        "teaserImg": "Panavas2023InvestigatingVisualUtility.png",
        "image": "Panavas2023InvestigatingVisualUtility.png",
        "imageDesc": "Based on expert examination of 1,200 differentially private scatterplots created using various parameter choices, we provide easy-to-use guidance for visualization practitiioners releasing private data. These charts illustrate how our results can be used to to create an optimal differentially private scatterplot.",
        "altText": "Illustration of an original scatterplot, how educated parameter choices affect the differentially private visualization, then how optimizing bin sizes affects visual utility, then how color scale optimization can play a role, then the final scatterplot.",
        "materials": {
          "PDF": "https://osf.io/b5zvn/download",
          "Preprint": "https://osf.io/b5zvn/",
          "DOI": "https://doi.org/10.1109/TVCG.2023.3292391",
          "Supplement": "https://osf.io/wej4s/",
          "Preregistration": "https://osf.io/25xhn",
          "Code": "https://github.com/VisDunneRight/Privacy-Plot-Viewer"
        }
      },
      {
        "title": "Concise Provenance of Interactive Network Analysis",
        "authors": ["Takanori Fujiwara", "Tarik Crnovrsanin", "Kwan-Liu Ma"],
        "hashLink": "Concise-Provenance",
        "venue": "Visual Informatics 2(4)",
        "year": "2018",
        "url": "https://www.sciencedirect.com/science/article/pii/S2468502X1830055X",
        "image": "concise.png",
        "materials": {
          "PDF": "https://pdf.sciencedirectassets.com/315710/1-s2.0-S2468502X19X00029/1-s2.0-S2468502X1830055X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjECgaCXVzLWVhc3QtMSJHMEUCIQDB2Z9%2BdZA51XDp1MU7OoEbg1jhUoawlqCVwLvazAWZwQIgGxxg3mQD%2F31ghJ3aE45tobyxHhy3Y8NukuemHC%2BGk5cqvAUI4P%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAFGgwwNTkwMDM1NDY4NjUiDLoQ0goZ25rMwlg6eiqQBdi1oRlqBn3yP2ESQmXCYWh1NqUewfTjG1XWAzHhD3zzrpCaw1JihNeAuVWm0Arctz%2BBzA%2BFEqOc0NqUn8AzYX3KDM2VGMDGuIlIE57dK7IX%2FZF7KTm2J2%2FOmcHaozanaKhSVxUOappxfCcPnl0LdSQSEXPhcMRAM3Yum2Do2MGpUZ0Hy8y8J9qLe1KncvwkSG88PMdbPFGtSgW0xzr2%2Byxo4o8gP0yfvAosg08Cq0W93M7er3c1ymR7P1ufW3QrPzMwxNAdSu8MnkSPwrVH2PNP4Ou0gmoPTBHc5ph7Xpn2ZNBfLzxQqdXPJaOekHibdHTA7NAdls6aqQ1wdO7kIUi%2FhbDuJluMFne7QFRt%2FI2rPXbDNSKC3Yv1YtvSqcEox%2Fqg4CvUyfCrG6ZLUfrAZs3aXA11qWMrvzIRFjxAWnpi43bnmxNe%2Bhl6KmnaRKM5JUjTTPuTeZ96ctXOVZ6ukxyJqPiq2LVcP21J9s8kdLSVaD1on3rIMWPOHwuW1aJkIB6thp5adrGwl5%2Bc%2Frka0Qu%2FNtW8e6UixepuZVMYwWhAesA4u5SvtfcMVpaRjl7ZptJ1N4t4noncWLk%2FgNohJkfCEWkIYMZ%2BVcf4cCjaHtNy%2FT1aXacsXth%2Fp29kDO%2B6FHxqZFm4pj2RKGO2S4AlR7zxPAkqwGsdefj%2FkH9m8Xij9uNXoO4X%2FbH1QxAWTBD9WGPIThn2FoWNUV7JrahIRisbhI1cQmA%2BAbEE%2F2hE5euvLU5mgqtZWwpWNxREVO3G3mqTX42n4v1bwNgoCBVEAK1izfmGq%2F6w3pG9%2FgeFZZQ%2B6zLuwcAItCaPcM8RBXvzhRjwFAroAp2Tr5XJ7EIPBcnLTZyq5yi%2FVVAsEPVrYUciMMW9260GOrEBkS1riFaAUU5r4gwEEGr0fQMAFjlL5M2LXBZM1r3xqj6JV6SOqIQdWlFfjmKVeLSqeynVm4sRMIcs%2BUAVD9fWoeaH9oKJSEodzFX0AVEgljwmRBG21MXz4yesfq5Kw8Ouh2zR4gOMCtdRnT3VgaFt%2B%2Fz63Q89TbLUaPBiIo9SlENTc%2BxUGdp8dfESAeqhGDCUhpvBfJpqHeqG1lZVqg2VWt41m3AT%2F%2BNMV%2FLPvogHrWEQ&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240129T000146Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYRV2YN76X%2F20240129%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=971b4d4825082005757b00c0fd5427ee00c8ca1b978b3ac2239c8abedf1bd22a&hash=41096012d72250f872f05665112ccb0624524162830dd6d6d47efd45184af1d9&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S2468502X1830055X&tid=spdf-cf08df02-0e56-4f06-8e30-2917859f4907&sid=cfcdf5324fce734f517b8c27252702c23d67gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=17105d550505555d07&rr=84cd33dbc89f4d0b&cc=us",
          "Preprint": "",
          "DOI": "https://doi.org/10.1016/j.visinf.2018.12.002",
          "Supplement": "https://takanori-fujiwara.github.io/s/prov-vis/index.html",
          "Video Preview": "https://youtu.be/u_kq2-pd8u0"
        }
      },
      {
        "title": "An Incremental Layout Method for Visualizing Online Dynamic Graphs",
        "authors": ["Tarik Crnovrsanin", "Jacqueline Chu", "Kwan-Liu Ma"],
        "hashLink": "Incremental-Layout",
        "venue": "Journal Graph Algorithm Application (JGAA), 21(1)",
        "year": "2017",
        "url": "http://jgaa.info/accepted/2017/CrnovrsaninChuMa2017.21.1.pdf",
        "image": "Incremental.png",
        "materials": {
          "PDF": "https://jgaa.info/accepted/2017/CrnovrsaninChuMa2017.21.1.pdf",
          "DOI": "https://doi.org/10.7155/jgaa.00406"
        }
      },
      {
        "title": "Visualization Techniques for Categorical Analysis of Social Networks with Multiple Edge Sets",
        "authors": [
          "Tarik Crnovrsanin",
          "Chris Muelder",
          "Bob Faris",
          "Diane Felmlee",
          "Kwan-Liu Ma"
        ],
        "hashLink": "Categorical-Networks",
        "venue": "Social Networks, vol. 37",
        "year": "2014",
        "url": "https://www.sciencedirect.com/science/article/abs/pii/S0378873313001044",
        "image": "SocialNetworks.png",
        "materials": {
          "PDF": "https://www.sciencedirect.com/science/article/abs/pii/S0378873313001044",
          "DOI": "https://doi.org/10.1016/j.socnet.2013.12.002"
        }
      },
      {
        "title": "Visual Reasoning about Social Networks using Centrality Sensitivities",
        "authors": ["Carlos D. Correa", "Tarik Crnovrsanin", "Kwan-Liu Ma"],
        "hashLink": "Sensitivities-Networks",
        "venue": "IEEE Transactions on Visualization and Computer Graphics—TVCG",
        "year": "2012",
        "url": "https://ieeexplore.ieee.org/document/5669304",
        "image": "VisualReasoning.png",
        "materials": {
          "PDF": "https://ieeexplore.ieee.org/document/5669304",
          "Preprint": "http://www.carloscorrea.com/docs/tvcg2011.pdf",
          "DOI": "https://doi.org/10.1109/tvcg.2010.260"
        }
      }
    ],
    "conference": [
      {
        "urlId": "Puerta2024EffectOrientationReadability",
        "title": "The effect of orientation on the readability and comfort of 3D-printed braille",
        "year": "2024",
        "authors": [
          "Eduardo Puerta",
          "Tarik Crnovrsanin",
          "Laura South",
          "Cody Dunne"
        ],
        "venue": "In Proc. CHI Conference on Human Factors in Computing Systems—CHI",
        "abstract": "Fused Deposition Modeling (FDM) is a low-cost method of 3D printing that involves stacking horizontal layers of plastic. FDM is used to produce tactile graphics and interfaces for people with visual impairments. Unfortunately, the print orientation can alter the structure and quality of braille and text. The difference between printing braille vertically and horizontally has been documented. However, we found no comprehensive study of these angles or the angles in between, nor any study providing a quantitative and qualitative user evaluation. We conducted two mixed-methods studies to evaluate the performance of braille printed at different angles. We measured reading time and subjective preference and performed a thematic analysis of participants' responses. Our participants were faster using and preferred 75° and vertical braille over horizontal braille. These results provide makers with guidelines for creating models with readable 3D-printed braille.",
        "teaserImg": "braillethumbnail.png",
        "image": "braillethumbnail.png",
        "imageDesc": "The shape of a 3D-printed object is affected by its orientation, as shown by the top left image. Therefore, we designed two experiments to determine if this impacted the experience of braille readers. These experiments differed by whether the stimuli were sanded, as shown in the top middle illustration. On the top right is a sketch of our experimental setup. Finally, below are some photographs of the experiment stimuli. ",
        "altText": "Hand-drawn sketches of various elements of the experiment. On the left, the drawings depict the differences between a braille cell's theoretical and actual shapes. In the middle, the sketches show a depiction of a sander, and the annotations read: two sanded experiments (sanded and unsanded). On the right, the drawings show the experimental setup, including a sketch of the table and the page of braille with the stimulus. At the bottom are a side view of the printer with plates printed at various angles, and a front view of the braille in one print.",
        "award": "",
        "materials": {
          "PDF": "https://osf.io/preprints/osf/vbqsg/download",
          "Preprint": "https://osf.io/preprints/osf/vbqsg",
          "DOI": "https://doi.org/10.1145/3613904.3642719",
          "Supplement": "https://osf.io/t2rbq/",
          "Preregistration": "https://osf.io/mcyv5",
          "Code": "",
          "Homepage": "",
          "Video preview": "",
          "Demo video": "",
          "Video presentation": "",
          "Award": "",
          "Reproducibility report": "",
          "University news": "",
          "News": "",
          "Other links": ""
        }
      },
      {
        "title": "Indy Survey Tool: A framework to unearth correlations in survey data",
        "year": "2023",
        "authors": [
          "Tarik Crnovrsanin",
          "Sara Di Bartolomeo",
          "Connor Wilson",
          "Cody Dunne"
        ],
        "hashLink": "Indy-Survey",
        "venue": "IEEE Transactions on Visualization and Computer Graphics—VIS",
        "abstract": "Survey companion websites allow users to explore collected survey information more deeply, as well as update or add entries for papers. These sites can help information stay relevant past the original release date of the survey paper. However, creating and maintaining a website can be laborious and difficult, especially when authors might not be experienced with programming. We introduce Indy Survey Tool to help authors develop companion websites for survey papers across diverse fields of study. The tool's core aim is to identify correlations between categorizations of papers. To accomplish this, the tool offers multiple combined filters and correlation matrix visualizations that enable users to explore the data from diverse perspectives. The tool's visualizations, list of papers, and filters are harmoniously integrated and highly responsive, providing users with feedback based on their selections. Identifying correlations in survey papers is a pivotal aspect of research, as it can enable the recognition of common combinations of categorizations within the papers—as well as highlight any omissions. The versatility of Indy Survey Tool enables researchers to delve into the correlations between categorizations in survey data, an essential aspect of research that can reveal gaps in the literature and highlight promising areas for future exploration. A preprint and supplemental material for the paper can be found at <a href=\"https://osf.io/tdhqn\">osf.io/tdhqn</a>.",
        "teaserImg": "Crnovrsanin2023IndySurveyTool.png",
        "image": "Crnovrsanin2023IndySurveyTool.png",
        "imageDesc": "An example of how the Indy Survey Tool we present was used in recent survey on Immersive Analytics. The left panel lets users filter using a search bar, timeline, and topic selector. The top bar provides information about the survey and how to add new entries. The center  shows a short summary of each included paper. The collapsible visualization panel on the right shows a correlation matrix for two selected dimensions. Interacting with the left and right panels filters the papers displayed in the center. Upon selection of a paper, a detail view pops up with all of its information (not shown).",
        "altText": "Screenshot of Indy Survey tool showing filter sliders, scented widgets, and other filter widgets on the left; a list of papers in the middle; and an adjacency matrix on the right.",
        "materials": {
          "PDF": "https://osf.io/um9gs/download",
          "Preprint": "https://osf.io/um9gs/",
          "Supplement": "https://osf.io/tdhqn/",
          "Code": "https://github.com/VisDunneRight/Indy-Survey-Tool",
          "DOI": "https://doi.org/10.1109/VIS54172.2023.00038"
        }
      },
      {
        "title": "A collection of benchmark datasets for evaluating graph layout algorithms",
        "year": "2023",
        "authors": [
          "Sara Di Bartolomeo",
          "Eduardo Puerta",
          "Connor Wilson",
          "Tarik Crnovrsanin",
          "Cody Dunne"
        ],
        "hashLink": "Collection-Benchmark",
        "venue": "Poster at Graph Drawing and Network Visualization—GD Posters",
        "abstract": "We built a website to help graph drawing researchers find benchmark datasets to use for evaluating graph layout algorithms.",
        "teaserImg": "DiBartolomeo2023CollectionBenchmarkDatasets.png",
        "image": "DiBartolomeo2023CollectionBenchmarkDatasets.png",
        "imageDesc": "We made a website collecting and compiling datasets used in Graph Drawing literature, find it at <a href=\"https://visdunneright.github.io/gd_benchmark_sets/\">https://visdunneright.github.io/gd_benchmark_sets/</a>.",
        "altText": "Comic depicting motivation for website and a screenshot of website.",
        "award": "GD 2023 best poster honorable mention!",
        "materials": {
          "PDF": "https://osf.io/yftju/download",
          "Preprint": "https://osf.io/yftju/",
          "DOI": "",
          "Supplement": "https://osf.io/j7ucv/",
          "Code": "https://osf.io/j7ucv/",
          "Homepage": "https://visdunneright.github.io/gd_benchmark_sets/",
          "Award": "Best poster honorable mention!"
        }
      },
      {
        "title": "Unraveling the design space of immersive analytics: a systematic review",
        "year": "2023",
        "authors": [
          "David Saffo",
          "Sara Di Bartolomeo",
          "Tarik Crnovrsanin",
          "Laura South",
          "Justin Raynor",
          "Caglar Yildirim",
          "Cody Dunne"
        ],
        "hashLink": "IA-Review",
        "venue": "IEEE Transactions on Visualization and Computer Graphics—TVCG",
        "abstract": "Immersive analytics has emerged as a promising research area, leveraging advances in immersive display technologies and techniques, such as virtual and augmented reality, to facilitate data exploration and decision-making. This paper presents a systematic literature review of 73 studies published between 2013-2022 on immersive analytics systems and visualizations, aiming to identify and categorize the primary dimensions influencing their design. We identified five key dimensions: Academic Theory and Contribution, Immersive Technology, Data, Spatial Presentation, and Visual Presentation. Academic Theory and Contribution assess the motivations behind the works and their theoretical frameworks. Immersive Technology examines the display and input modalities, while Data dimension focuses on dataset types and generation. Spatial Presentation discusses the environment, space, embodiment, and collaboration aspects in IA, and Visual Presentation explores the visual elements, facet and position, and manipulation of views. By examining each dimension individually and cross-referencing them, this review uncovers trends and relationships that help inform the design of immersive systems visualizations. This analysis provides valuable insights for researchers and practitioners, offering guidance in designing future immersive analytics systems and shaping the trajectory of this rapidly evolving field. A free copy of this paper and all supplemental materials are available at <a href=\"https://osf.io/5ewaj\">osf.io/5ewaj</a>.",
        "teaserImg": "Saffo2023UnravelingDesignSpace.png",
        "image": "Saffo2023UnravelingDesignSpace.png",
        "imageDesc": "The co-occurrences of codes, appearing in 8 or more surveyed papers, across five design dimensions of immersive analytics (IA) systems and visualizations. The codes found in each category combine to represent the unique design choices possible in the vast IA design space. These vignettes demonstrate how different codes sum to IA designs found within the academic literature.",
        "altText": "Large adjacency matrix of several contribution types by other factors considered in the survey with illustrative examples of several papers classified.",
        "materials": {
          "PDF": "https://osf.io/2e9x4/download",
          "Preprint": "https://osf.io/2e9x4/",
          "DOI": "https://doi.org/10.1109/TVCG.2023.3327368",
          "Supplement": "https://osf.io/5ewaj/",
          "Code": "https://github.com/VisDunneRight/IADesign.Space",
          "Homepage": "https://iadesign.space/"
        }
      },
      {
        "title": "Juvenile graphical perception: A comparison between children and adults",
        "year": "2022",
        "authors": [
          "Liudas Panavas",
          "Amy Worth",
          "Tarik Crnovrsanin",
          "Tejas Sathyamurthi",
          "Sara Cordes",
          "Michelle A. Borkin",
          "Cody Dunne"
        ],
        "hashLink": "Juvenile-Perception",
        "venue": "In Proc. CHI Conference on Human Factors in Computing Systems—CHI",
        "abstract": "Data visualization is pervasive in the lives of children as they encounter graphs and charts in early education and online media. In spite of this prevalence, our guidelines and understanding of how children perceive graphs stem primarily from studies conducted with adults. Previous psychology and education research indicates that children’s cognitive abilities are different from adults. Therefore, we conducted a classic graphical perception study on a population of children aged 8–12 enrolled in the Ivy After School Program in Boston, MA and adult computer science students enrolled in Northeastern University to determine how accurately participants judge differences in particular graphical encodings.We record the accuracy of participants’ answers for five encodings most commonly used with quantitative data. The results of our controlled experiment show that children have remarkably similar graphical perception to adults, but are consistently less accurate at interpreting the visual encodings. We found similar effectiveness rankings, relative differences in error between the different encodings, and patterns of bias across encoding types. Based on our findings, we provide design guidelines and recommendations for creating visualizations for children. This paper and all supplemental materials are available at <a href=\"https://osf.io/ygrdv/\">osf.io/ygrdv</a>.",
        "teaserImg": "Panavas2022JuvenileGraphicalPerception.png",
        "image": "Panavas2022JuvenileGraphicalPerception.png",
        "imageDesc": "Illustration of a designer thinking about Cleveland & McGill's guidelines when creating visualizations for students.",
        "altText": "Designer thinking about Cleveland & McGill's guidelines",
        "materials": {
          "PDF": "https://osf.io/r3dy2/download",
          "Preprint": "https://osf.io/r3dy2",
          "DOI": "https://doi.org/10.1145/3491102.3501893",
          "Supplement": "https://osf.io/ygrdv/",
          "Video Preview": "https://osf.io/k5bcw/",
          "Video Presentation": "https://osf.io/xjwz3/"
        }
      },
      {
        "title": "Visual utility evaluation of differentially private scatterplots",
        "year": "2022",
        "authors": [
          "Liudas Panavas",
          "Tarik Crnovrsanin",
          "Jane Adams",
          "Ali Sargavad",
          "Melanie Tory",
          "Cody Dunne"
        ],
        "hashLink": "Visual-Differentially",
        "venue": "IEEE Transactions on Visualization and Computer Graphics—VIS Posters",
        "abstract": "Differentially private scatterplots enable the plotting of two attributes while guaranteeing a specified level of privacy. What a user sees from the scatterplot can be affected by which privacy algorithm is used and how it adds noise to the data. However, there is no existing work that quantifies this effect. We present the results of a pilot data study that compares the visual utility of algorithms that create differentially private scatterplots. We compare five popular algorithms across a range of parameters. The results indicate that DAWA and Geometric Truncated are the best algorithms for visual utility. Future research could focus on optimizing the different parameters to maximize utility of the visual representations.",
        "teaserImg": "Panavas2022VisualUtilityEvaluation.png",
        "image": "Panavas2022VisualUtilityEvaluation.png",
        "imageDesc": "This diagram shows the process of how a regular scatterplot becomes private when a differential privacy algorithm is applied.",
        "altText": "Differential privacy pipeline on a scatterplot",
        "materials": {
          "PDF": "https://osf.io/5t68s/download",
          "Preprint": "https://osf.io/5t68s/",
          "DOI": "https://doi.org/10.31219/osf.io/5t68s",
          "Supplement": "https://osf.io/w7ng4/",
          "Poster": "https://osf.io/q7w42"
        },
        "note": "Preprint & supplemental material: https://osf.io/5t68s/"
      },
      {
        "title": "The state of the art in BGP visualization tools: a mapping of visualization techniques to cyberattack types",
        "authors": [
          "Justin Raynor",
          "Tarik Crnovrsanin",
          "Sara Di Bartolomeo",
          "Laura South",
          "David Saffo",
          "Cody Dunne"
        ],
        "hashLink": "BGP-STAR",
        "venue": "IEEE Transactions on Visualization and Computer Graphics—VIS",
        "year": "2022",
        "url": "https://ieeexplore.ieee.org/document/9904432",
        "image": "Raynor2022StateArtBgp.png",
        "materials": {
          "PDF": "https://osf.io/pkqc9/download",
          "Preprint": "https://osf.io/pkqc9/",
          "DOI": "https://doi.org/10.1109/TVCG.2022.3209412",
          "Supplement": "https://osf.io/tupz6/",
          "Video Preview": "https://www.youtube.com/watch?v=bdBozK2R0Oo",
          "Video Preview (Archive)": "https://osf.io/9m8ce/",
          "Video Presentation": "https://osf.io/gwjq3/"
        }
      },
      {
        "title": "Staged Animation Strategies for Online Dynamic Networks",
        "authors": [
          "Tarik Crnovrsanin",
          "Shilpika S Chandrasegaran",
          "Kwan-Liu Ma"
        ],
        "hashLink": "Staged-Dynamic",
        "venue": "IEEE Information Visualization Conference (InfoVis)",
        "year": "2020",
        "url": "https://arxiv.org/abs/2009.02005",
        "image": "stagedAnimation.png",
        "materials": {
          "PDF": "https://ieeexplore.ieee.org/document/9231268",
          "Preprint": "https://arxiv.org/abs/2009.02005",
          "DOI": "https://doi.org/10.1109/TVCG.2020.3030385"
        }
      },
      {
        "title": "An Interactive System for Exploring Historical Fire Data",
        "authors": [
          "Maksim Gomov",
          "Tarik Crnovrsanin",
          "Keshav Dasu",
          "Kwan-Liu Ma"
        ],
        "hashLink": "Fire-System",
        "venue": "IEEE Pacific Visualization Symposium (PacificVis)",
        "year": "2019",
        "url": "https://ieeexplore.ieee.org/document/8781588",
        "image": "Historical.png",
        "materials": {
          "PDF": "https://ieeexplore.ieee.org/document/8781588",
          "DOI": "https://doi.org/10.1109/PacificVis.2019.00040"
        }
      },
      {
        "title": "What Would a Graph Look Like in this Layout? A Machine Learning Approach to Large Graph Visualization",
        "authors": ["Oh-Hyun Kwon", "Tarik Crnovrsanin", "Kwan-Liu Ma"],
        "hashLink": "GraphML",
        "venue": "IEEE Transactions on Visualization and Computer Graphics—VIS",
        "year": "2018",
        "image": "GraphLook.png",
        "materials": {
          "PDF": "https://arxiv.org/pdf/1710.04328.pdf",
          "Preprint": "https://arxiv.org/abs/1710.04328",
          "DOI": "https://doi.org/10.1109/TVCG.2017.2743858",
          "Supplement": "http://kwon.cs.ucdavis.edu/wgl",
          "Video Preview": "https://vimeo.com/230840405",
          "Code": "https://github.com/VIDILabs/glam"
        }
      },
      {
        "title": "An Incremental Layout Method for Visualizing Online Dynamic Graphs",
        "authors": ["Tarik Crnovrsanin", "Jacqueline Chu", "Kwan-Liu Ma"],
        "hashLink": "Incremental-Layout-Conference",
        "venue": "Conference on Graph Drawing and Network Visualization",
        "year": "2015",
        "url": "https://vis.cs.ucdavis.edu/papers/tarik_incremental.pdf",
        "image": "Incremental.png",
        "award": "GD 2015 Best paper award",
        "materials": {
          "PDF": "https://dl.acm.org/doi/10.1007/978-3-319-27261-0_2",
          "Preprint": "https://vis.cs.ucdavis.edu/papers/tarik_incremental.pdf",
          "DOI": "https://doi.org/10.1007/978-3-319-27261-0_2"
        }
      },
      {
        "title": "A System for Visual Analysis of Radio Signal Data",
        "authors": ["Tarik Crnovrsanin", "Chris Muelder", "Kwan-Liu Ma"],
        "hashLink": "Radio-System",
        "venue": "Conference on Visual Analytics Science and Technology (VAST)",
        "year": "2014",
        "url": "https://ieeexplore.ieee.org/document/7042479/",
        "materials": {
          "DOI": "https://doi.org/10.1109/VAST.2014.7042479",
          "Video Preview": "https://vimeo.com/104495491"
        },
        "image": "RadioSignal.png"
      },
      {
        "title": "Stimulating a Blink: Reduction of Eye Fatigue with Visual Stimulus",
        "hashLink": "Blink-Reduction",
        "authors": ["Tarik Crnovrsanin", "Yang Wang", "Kwan-Liu Ma"],
        "venue": "In Proc. CHI Conference on Human Factors in Computing Systems—CHI",
        "year": "2014",
        "url": "http://vis.cs.ucdavis.edu/papers/blink.pdf",
        "image": "Stimulating.png",
        "materials": {
          "PDF": "http://vis.cs.ucdavis.edu/papers/blink.pdf",
          "DOI": "https://doi.org/10.1145/2556288.2557129",
          "Video Preview": "https://www.youtube.com/watch?v=WXFYEfxMF8I"
        }
      },
      {
        "title": "Egocentric Storylines for Visual Analysis of Large Dynamic Graphs",
        "hashLink": "Egocentric-Storylines",
        "authors": [
          "Chris Muelder",
          "Tarik Crnovrsanin",
          "Arnaud Sallaberry",
          "Kwan-Liu Ma"
        ],
        "venue": "IEEE Workshop on Big Data Visualization",
        "year": "2013",
        "url": "https://ieeexplore.ieee.org/document/6691715",
        "image": "Egocentric.png",
        "materials": {
          "PDF": "https://vis.cs.ucdavis.edu/papers/bdv2013-muelder.pdf",
          "DOI": "https://doi.org/10.1109/BigData.2013.6691715"
        }
      },
      {
        "title": "Visual Recommendations for Network Navigation",
        "authors": [
          "Tarik Crnovrsanin",
          "Isaac Liao",
          "Yingcai Wu",
          "Kwan-Liu Ma"
        ],
        "hashLink": "Visual-Recommendations",
        "venue": "In Proceedings of the Eurovis, vol. 30",
        "year": "2011",
        "url": "http://vis.cs.ucdavis.edu/papers/visual_recommendation.pdf",
        "image": "Recommendations.png",
        "materials": {
          "PDF": "https://onlinelibrary.wiley.com/doi/10.1111/j.1467-8659.2011.01957.x",
          "PrePrint": "http://vis.cs.ucdavis.edu/papers/visual_recommendation.pdf",
          "DOI": "http://dx.doi.org/10.1111/j.1467-8659.2011.01957.x"
        }
      },
      {
        "title": "Social Network Discovery based on Sensitivity Analysis",
        "authors": ["Tarik Crnovrsanin", "Carlos D. Correa", "Kwan-Liu Ma"],
        "hashLink": "Sensitivity-Discovery",
        "venue": "Proceedings International Conference of Advances in Social Networks Analysis and Mining (ASONAM)",
        "year": "2009",
        "url": "https://ieeexplore.ieee.org/document/5231923",
        "image": "Sensitivity.png",
        "materials": {
          "PDF": "https://ieeexplore.ieee.org/document/5231923",
          "DOI": "https://doi.org/10.1109/ASONAM.2009.56"
        }
      },
      {
        "title": "Proximity-based Visualization of Movement Trace Data",
        "authors": [
          "Tarik Crnovrsanin",
          "Chris Muelder",
          "Carlos D. Correa",
          "Kwan-Liu Ma"
        ],
        "hashLink": "Proximity-Movement",
        "venue": "Conference on Visual Analytics Science and Technology (VAST)",
        "year": "2009",
        "url": "https://ieeexplore.ieee.org/document/5332593",
        "image": "Proximity.png",
        "materials": {
          "PDF": "https://ieeexplore.ieee.org/document/5332593",
          "PrePrint": "http://www.carloscorrea.com/docs/proxivis.pdf",
          "DOI": "https://doi.org/10.1109/VAST.2009.5332593"
        }
      }
    ],
    "others": [
      {
        "title": "Method and apparatus for providing contextual rendering of a map",
        "authors": [
          "Vidya Setlur",
          "Cynthia Kuo",
          "Agathe Battestini",
          "Tarik Crnovrsanin"
        ],
        "hashLink": "context-map",
        "venue": "US Patent",
        "year": "2017",
        "url": "https://patents.google.com/patent/US9710961B2/en",
        "image": "MethodMap.png",
        "materials": {
          "PDF": "https://patentimages.storage.googleapis.com/00/53/09/26d33d301fbc1e/US9710961.pdf"
        }
      },
      {
        "title": "Cell phone mini challenge award: Intuitive social network graphs visual analytics of cell phone data using mobivis and ontovis",
        "authors": [
          "Carlos D Correa",
          "Tarik Crnovrsanin",
          "Christopher Muelder",
          "Zeqian Shen",
          "Ryan Armstrong",
          "James Shearer",
          "Kwan-Liu Ma"
        ],
        "hashLink": "cell-award",
        "venue": "IEEE Symposium on Visual Analytics Science and Technology",
        "year": "2008",
        "url": "https://ieeexplore.ieee.org/abstract/document/4677391",
        "image": "cell-phone.png",
        "materials": {
          "PDF": "https://ieeexplore.ieee.org/abstract/document/4677391"
        }
      }
    ]
  },
  "volunteer": [
    {
      "organization": "Startup Founders",
      "position": "Mentor",
      "website": "http://hooli.com",
      "location": "San Francisco, CA",
      "summary": "Mentoring startup founders to help them launch and grow their companies.",
      "startDate": "2014-04-01",
      "endDate": "2019-12-01",
      "start": {
        "year": 2014,
        "month": 4
      },
      "end": {
        "year": 2019,
        "month": 12
      },
      "highlights": []
    }
  ],
  "awards": [
    {
      "title": "GGCS Best Graduate Researcher Award",
      "summary": "Recieved in 2015 at University of California, Davis"
    },
    {
      "title": "Best Paper Award in 23rd International Symposium on Graph Drawing and Network Visualization",
      "summary": "Recieved in 2015 for the paper \"An Incremental Layout Method for Visualizing Online Dynamic Graphs\"."
    },
    {
      "title": "GGCS Graduate Fellowship",
      "summary": "Recieved in 2009, 2014 at University of California, Davis"
    },
    {
      "title": "Intuitive Social Network Graphs in VAST 2008 Challenge",
      "summary": "Recieved in 2008 with Carlos D. Correa, Chris Muelder, James Shearer, Kwan-Liu Ma."
    }
  ],
  "press": [],
  "languages": [],
  "interests": [],
  "references": []
}
